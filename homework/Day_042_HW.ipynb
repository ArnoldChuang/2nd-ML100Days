{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [範例重點]\n",
    "了解機器學習建模的步驟、資料型態以及評估結果等流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "\n",
    "# 如果是分類問題，請使用 DecisionTreeClassifier，若為回歸問題，請使用 DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型四步驟\n",
    "\n",
    "在 Scikit-learn 中，建立一個機器學習的模型其實非常簡單，流程大略是以下四個步驟\n",
    "\n",
    "1. 讀進資料，並檢查資料的 shape (有多少 samples (rows), 多少 features (columns)，label 的型態是什麼？)\n",
    "    - 讀取資料的方法：\n",
    "        - **使用 pandas 讀取 .csv 檔：**pd.read_csv\n",
    "        - **使用 numpy 讀取 .txt 檔：**np.loadtxt \n",
    "        - **使用 Scikit-learn 內建的資料集：**sklearn.datasets.load_xxx\n",
    "    - **檢查資料數量：**data.shape (data should be np.array or dataframe)\n",
    "2. 將資料切為訓練 (train) / 測試 (test)\n",
    "    - train_test_split(data)\n",
    "3. 建立模型，將資料 fit 進模型開始訓練\n",
    "    - clf = DecisionTreeClassifier()\n",
    "    - clf.fit(x_train, y_train)\n",
    "4. 將測試資料 (features) 放進訓練好的模型中，得到 prediction，與測試資料的 label (y_test) 做評估\n",
    "    - clf.predict(x_test)\n",
    "    - accuracy_score(y_test, y_pred)\n",
    "    - f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 2 1 2 0 0 2 0 0 0 1 2 0 1 0 0 2 0 2 1 0 0 0 0 0 0 2 1 0 2 0 1 2 2\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:  [0.01796599 0.         0.05992368 0.92211033]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 DecisionTreeClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[作業重點]\n",
    "目前你應該已經要很清楚資料集中，資料的型態是什麼樣子囉！包含特徵 (features) 與標籤 (labels)。因此要記得未來不管什麼專案，必須要把資料清理成相同的格式，才能送進模型訓練。 今天的作業開始踏入決策樹這個非常重要的模型，請務必確保你理解模型中每個超參數的意思，並試著調整看看，對最終預測結果的影響為何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 Scikit-learn 內建的資料集\n",
    "wine = datasets.load_wine()\n",
    "boston = datasets.load_boston()\n",
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (178, 13)\n"
     ]
    }
   ],
   "source": [
    "# 使用葡萄酒資料\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# 觀察該資料集,共有13個 feature\n",
    "X = wine .data\n",
    "print(\"Data shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3      4     5     6     7     8     9     10    11  \\\n",
       "0  14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1  13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2  13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3  14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4  13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "       12  \n",
       "0  1065.0  \n",
       "1  1050.0  \n",
       "2  1185.0  \n",
       "3  1480.0  \n",
       "4   735.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pandas 套件將資料欄位印出\n",
    "import pandas as pd\n",
    "df_X = pd.DataFrame(X)\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wine.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0\n",
      " 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "# 使用分類模型，使用 DecisionTreeClassifier\n",
    "# criterion='gini', 衡量資料相似程度\n",
    "# splitter='best', 建造樹時，選擇節點的原则，預設是splitter='best'，選擇最好的特徵點分類\n",
    "# max_depth=None, 樹能生長的最深限制\n",
    "# min_samples_split=2, ⾄少要多少樣本以上才進⾏切分\n",
    "# min_samples_leaf=1, 最終的葉⼦ (節點) 上⾄少要有多少樣本\n",
    "# min_weight_fraction_leaf=0.0, 如果是0，則表示所有樣本的權重是一樣的\n",
    "# max_features=None, 劃分数據集時考虑的最多的特徵值数量\n",
    "# random_state=None,\n",
    "# max_leaf_nodes=None,\n",
    "# min_impurity_split=1e-07, 樹增長停止 threshold\n",
    "# class_weight=None,\n",
    "# presort=False, 在進行擬合前，是否預分数據來加快樹的建構\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=1, min_samples_split=2, min_samples_leaf=1 )\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "# 出現 error: Unknown label type: 'continuous' 因此後方加上 .astype('int')\n",
    "# clf.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 0 1 2 0 1 0 1 1 0 2 2 0 1 0 1 1 2 1 2 1 2 0 2 1 1 1 2 0 1 0 1 2 1 0\n",
      " 0 0 2 2 0 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "# 出現 error: Unknown label type: 'continuous' 因此後方加上 .astype('int')\n",
    "# clf.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:  [0.04440705 0.         0.         0.         0.         0.04296585\n",
      " 0.10004551 0.         0.         0.38107601 0.         0.04285558\n",
      " 0.38865   ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用回歸模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 0. 0. 1. 2. 0. 0. 0. 1. 1. 0. 2. 2. 0. 1. 0. 1. 1. 2. 1. 2. 1. 2.\n",
      " 0. 2. 1. 1. 2. 2. 0. 1. 0. 1. 2. 2. 0. 0. 0. 2. 2. 0. 0. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 使用回歸模型，使用 DecisionTreeRegressor\n",
    "Reg = DecisionTreeRegressor()\n",
    "\n",
    "# 訓練模型\n",
    "Reg.fit(x_train, y_train)\n",
    "# 出現 error: Unknown label type: 'continuous' 因此後方加上 .astype('int')\n",
    "# clf.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = Reg .predict(x_test)\n",
    "\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:  [0.01285659 0.         0.         0.         0.03685556 0.\n",
      " 0.61367513 0.         0.         0.08462354 0.         0.\n",
      " 0.25198917]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance: \", Reg.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ans: 1. 改變樹的參數會影響預測結果\n",
    "     2. 以wine的case來說,用DecisionTreeRegressor的結果會比DecisionTreeClassifier來的好"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
